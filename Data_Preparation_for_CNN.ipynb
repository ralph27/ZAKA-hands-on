{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralph27/ZAKA-hands-on/blob/master/Data_Preparation_for_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzPg64OS68GH"
      },
      "source": [
        "#Image Data Preparation\n",
        "Â© 2024, Zaka AI, Inc. All Rights Reserved.\n",
        "\n",
        "---\n",
        "\n",
        "**Objective:** This exercise explores on the Keras library's role in computer vision. It shows how to load and convert images with Keras, how to use the MNIST handwritten image classification dataset and how to employ the ImageDataGenerator class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hTR4-zq7quj"
      },
      "source": [
        "Let's start by getting our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4BfzSBhxrno",
        "outputId": "fe6adcd9-f1e6-44ce-fa99-09b0ca655252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# clone github repo\n",
        "!git clone https://github.com/zaka-ai/computer-vision-course.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'computer-vision-course'...\n",
            "remote: Enumerating objects: 2118, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 2118 (delta 0), reused 0 (delta 0), pack-reused 2115\u001b[K\n",
            "Receiving objects: 100% (2118/2118), 51.06 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (34/34), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeXPT00x5fg"
      },
      "source": [
        "## How to Load an Image with Keras\n",
        "\n",
        "Keras provides the `load_img()` function for loading an image from file as a PIL image object.\n",
        "\n",
        "The example below loads the Bondi Beach photograph from file as a PIL image and reports details about the loaded image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpdk60JCx6Kg",
        "outputId": "c898da1e-6fad-47ae-8edf-9ab0265b7cd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# example of loading an image with the Keras API\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "# load the image\n",
        "img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n",
        "img = load_img(img_path)\n",
        "\n",
        "# report details about the image\n",
        "print(type(img))\n",
        "print(img.format)\n",
        "print(img.mode)\n",
        "print(img.size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "JPEG\n",
            "RGB\n",
            "(640, 360)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUFT5m4Uy4lD"
      },
      "source": [
        "## How to Convert an Image With Keras\n",
        "\n",
        "Keras provides the `img_to_array()` function for converting a loaded image in PIL format into a NumPy array for use with deep learning models. The API also provides the `array_to_img()` function that can be used for converting a NumPy array of pixel data into a PIL image. This can be useful if the pixel data is modified in array format because it can be saved or viewed.\n",
        "\n",
        "The example below loads the test image, converts it to a NumPy array, and then converts it back into a PIL image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMCkviX-y453",
        "outputId": "7213f7a4-2737-4b0d-fc9f-eb44f42f4a37",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# example of converting an image with the Keras API\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# load the image\n",
        "img_path = \"computer-vision-course/deep_learning/data/image1.jpg\"\n",
        "img = load_img(img_path)\n",
        "print(type(img))\n",
        "\n",
        "# convert to numpy array\n",
        "img_array = img_to_array(img)\n",
        "print(img_array.dtype)\n",
        "print(img_array.shape)\n",
        "\n",
        "# convert back to image\n",
        "img_pil = array_to_img(img_array)\n",
        "print(type(img))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n",
            "float32\n",
            "(360, 640, 3)\n",
            "<class 'PIL.JpegImagePlugin.JpegImageFile'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWa5Q0jg1Cnt"
      },
      "source": [
        "## ImageDataGenerator Class"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ImageDataGenerator provides a suite of techniques for dealing with images such as scaling image pixels, applying pixel centering, applying augmentations, and many more!"
      ],
      "metadata": {
        "id": "UXrU90Yf4Ijr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBDZq60S74pM"
      },
      "source": [
        "### MNIST Handwritten Image Classification Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Spw_JyDG1GHa",
        "outputId": "7ef1fa73-b1a3-4862-c0ef-1dbd8439d327",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(trainX, trainY), (testX, testY) = mnist.load_data()\n",
        "\n",
        "# summarize dataset shape\n",
        "print(\"Train\", trainX.shape, trainY.shape)\n",
        "print(\"Test\", testX.shape, testY.shape)\n",
        "\n",
        "# summarize pixel values\n",
        "print(\"Train\", trainX.min(), trainX.max(), trainX.mean(), trainX.std())\n",
        "print(\"Test\", testX.min(), testX.max(), testX.mean(), testX.std())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n",
            "Train (60000, 28, 28) (60000,)\n",
            "Test (10000, 28, 28) (10000,)\n",
            "Train 0 255 33.318421449829934 78.56748998339798\n",
            "Test 0 255 33.791224489795916 79.17246322228644\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OpWYm9_m2o2x"
      },
      "source": [
        "### How to Normalize Images With ImageDataGenerator\n",
        "\n",
        "**Reshape dataset:** the MNIST dataset is loaded with number of samples, number of pixels in width and height but not number of channels. This is why we make sure that the ImageDataGenerator class and Keras functions receive datasets having the number of samples, the size and the depth all together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBappxlP2qBV"
      },
      "source": [
        "# reshape dataset to have a single channel because the ImageDataGenerator expects a numpy array of rank 4\n",
        "\n",
        "# trainX: (60000, 28, 28) => (60000, 28, 28, 1)\n",
        "# testX:  (10000, 28, 28) => (10000, 28, 28, 1)\n",
        "\n",
        "trainX = trainX.reshape((trainX.shape[0], trainX.shape[1], trainX.shape[2], 1))\n",
        "testX = testX.reshape((testX.shape[0], trainX.shape[1], trainX.shape[2], 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize dataset shape\n",
        "print(\"Train\", trainX.shape, trainY.shape)\n",
        "print(\"Test\", testX.shape, testY.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nRZymqf4mqh",
        "outputId": "34373308-d5fa-4c86-b303-aef15e543201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train (60000, 28, 28, 1) (60000,)\n",
            "Test (10000, 28, 28, 1) (10000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4s-8ZZPQDobF"
      },
      "source": [
        "**Rescale:** Normalize all the pixel values of the dataset to an interval of 0 to 1 instead of having small weight values when training deep learning networks for example and very large pixel values by comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_xCMpdjDpgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e60e988-d727-4b3f-e21a-2567341a81ba"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# confirm scale of pixels\n",
        "print('Train min=%.3f, max=%.3f' % (trainX.min(), trainX.max()))\n",
        "print('Test min=%.3f, max=%.3f' % (testX.min(), testX.max()))\n",
        "\n",
        "# create generator (1.0/255.0)\n",
        "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train min=0.000, max=255.000\n",
            "Test min=0.000, max=255.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, iterators can be created using the generator for both the train and test datasets. We will use a batch size of 64. This means that each of the train and test datasets of images are divided into groups of 64 images that will then be scaled when returned from the iterator.\n",
        "\n",
        "We can see how many batches there will be in one epoch, e.g. one pass through the training dataset, by printing the length of each iterator."
      ],
      "metadata": {
        "id": "DeRVaF2Q75mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare iterators to scale images\n",
        "train_iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "test_iterator = datagen.flow(testX, testY, batch_size=64)\n",
        "\n",
        "# 60000 / 64 = 937.5 ~= 938\n",
        "\n",
        "print('Batches train=%d, test=%d' % (len(train_iterator), len(test_iterator)))\n",
        "\n",
        "# confirm the scaling works\n",
        "batchX, batchy = train_iterator.next()\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lgxd9fsV78n4",
        "outputId": "5795eff1-4a71-46a3-ded0-8605403d03c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batches train=938, test=157\n",
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d5Yki093nEE"
      },
      "source": [
        "### How to Center Images With ImageDataGenerator\n",
        "**Center pixel values:** Find the mean of the pixel values and make sure all the pixels are distributed around it as if it were the new zero and the remaining values are positive and negative.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZly7t0W3pn9",
        "outputId": "119ac571-a28f-4b69-d84e-151a6b455de8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# report per-image mean\n",
        "print('Means train=%.3f, test=%.3f' % (trainX.mean(), testX.mean()))\n",
        "\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(trainX)\n",
        "print('Data Generator Mean: %.3f' % datagen.mean)\n",
        "\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=64)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Means train=33.318, test=33.791\n",
            "Data Generator Mean: 33.318\n",
            "(64, 28, 28, 1) -0.3496583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A better check would be to set the batch size to the size of the training dataset (e.g. 60,000 samples), retrieve one batch, then calculate the mean. It should be a very small value close to zero."
      ],
      "metadata": {
        "id": "JAd_dQEl9SdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(trainX, trainY, batch_size=len(trainX), shuffle=False)\n",
        "\n",
        "# get a batch\n",
        "batchX, batchy = iterator.next()\n",
        "\n",
        "# mean pixel value in the batch\n",
        "print(batchX.shape, batchX.mean())\n",
        "\n",
        "#display an image\n",
        "img2 = batchX[41]\n",
        "print(img2.shape)\n",
        "from google.colab.patches import cv2_imshow\n",
        "cv2_imshow(img2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "Yp1q3Nsw9I2o",
        "outputId": "63b9ee87-69b1-4618-df3f-722568d08909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1) -1.9512918e-05\n",
            "(28, 28, 1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACEElEQVR4nO2VP8hxURzHf+d6y3Pp+hPDTTHIwGCwKSWrFLdbTMqoZDQYDJKyKIqSVVlsBrIYKKUooqhzFxtFkiSl3Ge4Jb3+XM/z1Ns7PN/xe87v0/f0O79zAH71/4hl2clkwjDM/RLxPoUkSYqiKIq6dYLB4P3OP28SU6kUy7JSqZTn+e12a7fbBX+xWNxvRqI4nU6XTCZdLhcAIIR4ngcAm81WrVZpmr7Sv5DUbDbXarWPjw8AKJVKCCGn08kwTCQSMZvNm83mYZUItNFoXC6X8Xjs9/sBwGAwnE6nTCbjcrkkEkmr1RI96ANxHIcxjsfjV8doNGKMMcb5fP47RAAIh8MColKpKBQKpVLZ7XYxxp1OR6FQPKsSb1Qul/N4PACw2WwQQhqNZrlc+ny+3W73zaR/5eU4rtfrvcgo6K172u/3EUIAQBDEarXa7/c/harV6kKhwPP8er1GCOn1eplMdjweX5SIjKlSqazX6zRNL5dLt9tdqVRUKlU0Gv1R0larde3M9dQPp+jdpIlEQqvVAkA0Gr3t9e2b8jWow+EIhUIEQRSLxel0KphyuRwhNB6PX0OfKp1OY4zn87nFYhEckiQ5jmu326K1T5MKrMPhcD6fTSaT1+sdDAYAMBqNRKFPGzWbzaxWq0qlajabV7NcLmezWVHo0zFVq9WBQCAWi/E8PxwOZTLZw5/jV/9InyV4yQyMrM8DAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI0bIHsZ9UQB"
      },
      "source": [
        "## TASK: Load dataset images progressively\n",
        "In this task, we will code a Keras API set of instructions to progressively load data from disk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ba-SE6oU9YXA",
        "outputId": "ec2bf518-2867-43db-cc09-abd64a28f6f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# import IDG from Keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# create the data generator with rescale and iterators\n",
        "datagen = ImageDataGenerator(rescale = 1.0/255.0)\n",
        "train_it = datagen.flow_from_directory(\"computer-vision-course/deep_learning/dataset/train\", class_mode = \"binary\", batch_size = 2)\n",
        "test_it = datagen.flow_from_directory(\"computer-vision-course/deep_learning/dataset/test\", class_mode=\"binary\", batch_size=1)\n",
        "valid_it = datagen.flow_from_directory(\"computer-vision-course/deep_learning/dataset/validation\", class_mode=\"binary\", batch_size=1)\n",
        "\n",
        "# get batches for training\n",
        "batchX, batchY = train_it.next()\n",
        "# get info on batches\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "\n",
        "# testing batch\n",
        "batchX, batchy = test_it.next()\n",
        "# get info on batches\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))\n",
        "\n",
        "# validation batch\n",
        "batchX, batchy = valid_it.next()\n",
        "# get info on batches\n",
        "print('Batch shape=%s, min=%.3f, max=%.3f' % (batchX.shape, batchX.min(), batchX.max()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 20 images belonging to 2 classes.\n",
            "Found 4 images belonging to 2 classes.\n",
            "Found 10 images belonging to 2 classes.\n",
            "Batch shape=(2, 256, 256, 3), min=0.000, max=1.000\n",
            "Batch shape=(1, 256, 256, 3), min=0.000, max=1.000\n",
            "Batch shape=(1, 256, 256, 3), min=0.000, max=1.000\n"
          ]
        }
      ]
    }
  ]
}