{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ralph27/ZAKA-hands-on/blob/master/Word_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLRfLrVXtUTI"
      },
      "source": [
        "# Word Embeddings\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Â© 2024, Zaka AI, Inc. All Rights Reserved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caLGnxM2Ib_T"
      },
      "source": [
        "\n",
        "**Objective:** The goal from this exercise is to explore the Word2Vec technique for word embeddings and introduce Stanford's GloVe embedding as well. The libraries we will be using are `Gensim` for Word Embeddings Word2Vec and GloVe, `matplotlib` for visualization and `Scikit-Learn` for Principle Component Analysis models which are used for reducing dimensionality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj1QPhssIfi8"
      },
      "source": [
        "## Learn Word2Vec Embedding using Gensim\n",
        "\n",
        "Word2Vec models require a lot of text, e.g. the entire Wikipedia corpus. However, we will demonstrate the principles using a small in-memory example of text.\n",
        "\n",
        "Each sentence must be tokenized (divided into words and prepared). The sentences could be text loaded into memory, or an iterator that progressively loads text, required for very large text corpora.\n",
        "\n",
        "Word2Vec accepts several parameters that affect both training speed and quality:\n",
        "\n",
        "*   **`size`**: (default 100) The number of dimensions of the embedding, e.g. the length of the dense vector to represent each token (word).\n",
        "*   **`window`**: (default 5) The maximum distance between a target word and words around the target word.\n",
        "*   **`min_count`**: (default 5) The minimum count of words to consider when training the model; words with an occurrence less than this count will be ignored.\n",
        "*   **`workers`**: (default 3) The number of threads to use while training.\n",
        "*   **`sg`**: (default 0 or CBOW) The training algorithm, either CBOW (0) or skip gram (1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7pU1nY3LhkO"
      },
      "source": [
        "###Building and training a Word2Vec model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We would like to apply Word2Vec on few sentences with the default set of parameters except for the ***min_count*** which will be 1 in our case as the data is small."
      ],
      "metadata": {
        "id": "s5Bjuyz6lJEA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bY9k0TquxeHp",
        "outputId": "d043773a-67fe-444e-8ad8-d8734a349e2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "# define training data\n",
        "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
        "\t\t\t['yet', 'another', 'sentence'],\n",
        "\t\t\t['one', 'more', 'sentence'],\n",
        "\t\t\t['and', 'the', 'final', 'sentence']]\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(sentences, min_count=1)\n",
        "\n",
        "# summarize the loaded model\n",
        "print(model)\n",
        "\n",
        "# summarize vocabulary\n",
        "# the model.wv property holds the words-and-vectors\n",
        "#the vocabulary was in the vocab field of the Word2Vec model's wv property, as a dictionary, with the keys being each token (word).\n",
        "\n",
        "words = list(model.wv.index_to_key)\n",
        "\n",
        "print(words)\n",
        "\n",
        "# access vector for one word\n",
        "print(model.wv['sentence'])\n",
        "\n",
        "# save model\n",
        "\n",
        "model.save('model.bin')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec<vocab=14, vector_size=100, alpha=0.025>\n",
            "['sentence', 'the', 'is', 'this', 'final', 'and', 'more', 'one', 'another', 'yet', 'second', 'word2vec', 'for', 'first']\n",
            "[-5.3622725e-04  2.3643136e-04  5.1033497e-03  9.0092728e-03\n",
            " -9.3029495e-03 -7.1168090e-03  6.4588725e-03  8.9729885e-03\n",
            " -5.0154282e-03 -3.7633716e-03  7.3805046e-03 -1.5334714e-03\n",
            " -4.5366134e-03  6.5540518e-03 -4.8601604e-03 -1.8160177e-03\n",
            "  2.8765798e-03  9.9187379e-04 -8.2852151e-03 -9.4488179e-03\n",
            "  7.3117660e-03  5.0702621e-03  6.7576934e-03  7.6286553e-04\n",
            "  6.3508903e-03 -3.4053659e-03 -9.4640139e-04  5.7685734e-03\n",
            " -7.5216377e-03 -3.9361035e-03 -7.5115822e-03 -9.3004224e-04\n",
            "  9.5381187e-03 -7.3191668e-03 -2.3337686e-03 -1.9377411e-03\n",
            "  8.0774371e-03 -5.9308959e-03  4.5162440e-05 -4.7537340e-03\n",
            " -9.6035507e-03  5.0072931e-03 -8.7595852e-03 -4.3918253e-03\n",
            " -3.5099984e-05 -2.9618145e-04 -7.6612402e-03  9.6147433e-03\n",
            "  4.9820580e-03  9.2331432e-03 -8.1579173e-03  4.4957981e-03\n",
            " -4.1370760e-03  8.2453608e-04  8.4986202e-03 -4.4621765e-03\n",
            "  4.5175003e-03 -6.7869602e-03 -3.5484887e-03  9.3985079e-03\n",
            " -1.5776526e-03  3.2137157e-04 -4.1406299e-03 -7.6826881e-03\n",
            " -1.5080082e-03  2.4697948e-03 -8.8802696e-04  5.5336617e-03\n",
            " -2.7429771e-03  2.2600652e-03  5.4557943e-03  8.3459532e-03\n",
            " -1.4537406e-03 -9.2081428e-03  4.3705525e-03  5.7178497e-04\n",
            "  7.4419081e-03 -8.1328274e-04 -2.6384138e-03 -8.7530091e-03\n",
            " -8.5655687e-04  2.8265631e-03  5.4014288e-03  7.0526563e-03\n",
            " -5.7031214e-03  1.8588197e-03  6.0888636e-03 -4.7980510e-03\n",
            " -3.1072604e-03  6.7976294e-03  1.6314756e-03  1.8991709e-04\n",
            "  3.4736372e-03  2.1777749e-04  9.6188262e-03  5.0606038e-03\n",
            " -8.9173904e-03 -7.0415605e-03  9.0145587e-04  6.3925339e-03]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model was trained on 14 unique words where each word is represented by a vector of size 100."
      ],
      "metadata": {
        "id": "lQVDQWwhnbul"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjTGAuQC59K",
        "outputId": "62c7158d-4fcf-44c2-8201-eba51f67407b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# let's load the model and test it\n",
        "\n",
        "new_model = Word2Vec.load('model.bin')\n",
        "# load model and get the vectors of the words 'this' and 'is'\n",
        "print(new_model.wv['this','is'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-8.2426779e-03  9.2993546e-03 -1.9766092e-04 -1.9672764e-03\n",
            "   4.6036304e-03 -4.0953159e-03  2.7431143e-03  6.9399667e-03\n",
            "   6.0654259e-03 -7.5107943e-03  9.3823504e-03  4.6718083e-03\n",
            "   3.9661205e-03 -6.2435055e-03  8.4599797e-03 -2.1501649e-03\n",
            "   8.8251876e-03 -5.3620026e-03 -8.1294188e-03  6.8245591e-03\n",
            "   1.6711927e-03 -2.1985089e-03  9.5136007e-03  9.4938548e-03\n",
            "  -9.7740470e-03  2.5052286e-03  6.1566923e-03  3.8724565e-03\n",
            "   2.0227872e-03  4.3050171e-04  6.7363144e-04 -3.8206363e-03\n",
            "  -7.1402504e-03 -2.0888723e-03  3.9238976e-03  8.8186832e-03\n",
            "   9.2591504e-03 -5.9759365e-03 -9.4026709e-03  9.7643770e-03\n",
            "   3.4297847e-03  5.1661171e-03  6.2823449e-03 -2.8042626e-03\n",
            "   7.3227035e-03  2.8302716e-03  2.8710044e-03 -2.3803699e-03\n",
            "  -3.1282497e-03 -2.3701417e-03  4.2764368e-03  7.6057913e-05\n",
            "  -9.5842788e-03 -9.6655441e-03 -6.1481940e-03 -1.2856961e-04\n",
            "   1.9974159e-03  9.4319675e-03  5.5843508e-03 -4.2906962e-03\n",
            "   2.7831673e-04  4.9643586e-03  7.6983096e-03 -1.1442233e-03\n",
            "   4.3234206e-03 -5.8143795e-03 -8.0419064e-04  8.1000505e-03\n",
            "  -2.3600650e-03 -9.6634552e-03  5.7792603e-03 -3.9298222e-03\n",
            "  -1.2228728e-03  9.9805174e-03 -2.2563506e-03 -4.7570644e-03\n",
            "  -5.3293873e-03  6.9808899e-03 -5.7088719e-03  2.1136629e-03\n",
            "  -5.2556600e-03  6.1207139e-03  4.3573068e-03  2.6063549e-03\n",
            "  -1.4910829e-03 -2.7460635e-03  8.9929365e-03  5.2157748e-03\n",
            "  -2.1625196e-03 -9.4703101e-03 -7.4260519e-03 -1.0637414e-03\n",
            "  -7.9494715e-04 -2.5629092e-03  9.6827205e-03 -4.5852066e-04\n",
            "   5.8737611e-03 -7.4475873e-03 -2.5060738e-03 -5.5498634e-03]\n",
            " [ 9.4563962e-05  3.0773198e-03 -6.8126451e-03 -1.3754654e-03\n",
            "   7.6685809e-03  7.3464094e-03 -3.6732971e-03  2.6427018e-03\n",
            "  -8.3171297e-03  6.2054861e-03 -4.6373224e-03 -3.1641065e-03\n",
            "   9.3113566e-03  8.7338570e-04  7.4907029e-03 -6.0740625e-03\n",
            "   5.1605068e-03  9.9228229e-03 -8.4573915e-03 -5.1356913e-03\n",
            "  -7.0648370e-03 -4.8626517e-03 -3.7785638e-03 -8.5361991e-03\n",
            "   7.9556061e-03 -4.8439382e-03  8.4236134e-03  5.2625705e-03\n",
            "  -6.5500261e-03  3.9578713e-03  5.4701497e-03 -7.4265362e-03\n",
            "  -7.4057197e-03 -2.4752307e-03 -8.6257253e-03 -1.5815723e-03\n",
            "  -4.0343284e-04  3.2996845e-03  1.4418805e-03 -8.8142155e-04\n",
            "  -5.5940580e-03  1.7303658e-03 -8.9737179e-04  6.7936908e-03\n",
            "   3.9735902e-03  4.5294715e-03  1.4343059e-03 -2.6998555e-03\n",
            "  -4.3668128e-03 -1.0320747e-03  1.4370275e-03 -2.6460087e-03\n",
            "  -7.0737829e-03 -7.8053069e-03 -9.1217868e-03 -5.9351693e-03\n",
            "  -1.8474245e-03 -4.3238713e-03 -6.4606704e-03 -3.7173224e-03\n",
            "   4.2891586e-03 -3.7390434e-03  8.3781751e-03  1.5339935e-03\n",
            "  -7.2423196e-03  9.4337985e-03  7.6312125e-03  5.4932819e-03\n",
            "  -6.8488456e-03  5.8226790e-03  4.0090932e-03  5.1853694e-03\n",
            "   4.2559016e-03  1.9397545e-03 -3.1701624e-03  8.3538452e-03\n",
            "   9.6121803e-03  3.7926030e-03 -2.8369951e-03  7.1275235e-06\n",
            "   1.2188185e-03 -8.4583247e-03 -8.2239453e-03 -2.3101569e-04\n",
            "   1.2372875e-03 -5.7433806e-03 -4.7252737e-03 -7.3460746e-03\n",
            "   8.3286157e-03  1.2129784e-04 -4.5093987e-03  5.7017053e-03\n",
            "   9.1800150e-03 -4.0998720e-03  7.9646818e-03  5.3754342e-03\n",
            "   5.8791232e-03  5.1259040e-04  8.2130842e-03 -7.0190406e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We ended up with two vectors of size 100 each, representing the words 'this' and 'is' respectively."
      ],
      "metadata": {
        "id": "Egg-f7cxoe8_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moU2ue2iCCGm"
      },
      "source": [
        "### Visualize Word Embedding\n",
        "\n",
        "After learning the word embedding for the text, it's nice to explore it with visualization. However, the word embedding comes in a very high dimensionality. We can use classical projection methods to reduce the high-dimensional word vectors to two- dimensional plots and plot them on a graph.\n",
        "\n",
        "A method such as Principal Component Analysis (PCA) is normally implemented to reduce the dimensionality of word embedding.\n",
        "\n",
        "The visualizations can provide a qualitative diagnostic for our learned model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSr__Ji1Ilku",
        "outputId": "e548a5ff-bfe8-48ea-ae9e-3d53e6c9da4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from sklearn.decomposition import PCA\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define training data\n",
        "sentences = [['this', 'is', 'the', 'first', 'sentence', 'for', 'word2vec'],\n",
        "\t\t\t['this', 'is', 'the', 'second', 'sentence'],\n",
        "\t\t\t['yet', 'another', 'sentence'],\n",
        "\t\t\t['one', 'more', 'sentence'],\n",
        "\t\t\t['and', 'the', 'final', 'sentence']]\n",
        "\n",
        "# train model\n",
        "model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "\n",
        "# fit a 2D PCA model to the vectors\n",
        "\n",
        "X = model.wv[model.wv.index_to_key]\n",
        "\n",
        "#reduce dimensionality to 2D\n",
        " \t\t#2D model to plot\n",
        "pca= PCA(n_components=2)\n",
        "result = pca.fit_transform(X)\n",
        "\n",
        "\n",
        "# create a scatter plot of the projection\n",
        "# pull out the 2 dimensions as x and y\n",
        "\n",
        "pyplot.scatter(result[:,0], result[:,1])\n",
        "words = list(model.wv.index_to_key)\n",
        "\n",
        "\n",
        "# annotate the points on the graph with the words themselves\n",
        "for i, word in enumerate(words):\n",
        "\tpyplot.annotate(word, xy=(result[i, 0], result[i, 1]))\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLxMShJHJQIs"
      },
      "source": [
        "## Google Word2Vec\n",
        "\n",
        "Instead of training your own word vectors (which requires a lot of RAM and compute power), you can simply use a pre-trained word embedding. Google has published a pre-trained Word2Vec model that was trained on Google news data (about 100 billion words). It contains 3 million words and phrases and was fit using 300-dimensional word vectors. It is a 1.53 Gigabyte file."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install \"requests[security]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxcaHxbABjc6",
        "outputId": "69447a5d-da0c-4af6-f9c2-2a1d108102e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests[security] in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[security]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[security]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[security]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[security]) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NpK-fo1JQUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30098ad9-7905-4fc5-cd78-a73ae330558b"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fl1ZQHJHGIN"
      },
      "source": [
        "#### Let's have fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3kxqDMymKH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f70cc163-c350-4b75-a4a1-8cd5b816849d"
      },
      "source": [
        "# get word vector\n",
        "model['car']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.13085938,  0.00842285,  0.03344727, -0.05883789,  0.04003906,\n",
              "       -0.14257812,  0.04931641, -0.16894531,  0.20898438,  0.11962891,\n",
              "        0.18066406, -0.25      , -0.10400391, -0.10742188, -0.01879883,\n",
              "        0.05200195, -0.00216675,  0.06445312,  0.14453125, -0.04541016,\n",
              "        0.16113281, -0.01611328, -0.03088379,  0.08447266,  0.16210938,\n",
              "        0.04467773, -0.15527344,  0.25390625,  0.33984375,  0.00756836,\n",
              "       -0.25585938, -0.01733398, -0.03295898,  0.16308594, -0.12597656,\n",
              "       -0.09912109,  0.16503906,  0.06884766, -0.18945312,  0.02832031,\n",
              "       -0.0534668 , -0.03063965,  0.11083984,  0.24121094, -0.234375  ,\n",
              "        0.12353516, -0.00294495,  0.1484375 ,  0.33203125,  0.05249023,\n",
              "       -0.20019531,  0.37695312,  0.12255859,  0.11425781, -0.17675781,\n",
              "        0.10009766,  0.0030365 ,  0.26757812,  0.20117188,  0.03710938,\n",
              "        0.11083984, -0.09814453, -0.3125    ,  0.03515625,  0.02832031,\n",
              "        0.26171875, -0.08642578, -0.02258301, -0.05834961, -0.00787354,\n",
              "        0.11767578, -0.04296875, -0.17285156,  0.04394531, -0.23046875,\n",
              "        0.1640625 , -0.11474609, -0.06030273,  0.01196289, -0.24707031,\n",
              "        0.32617188, -0.04492188, -0.11425781,  0.22851562, -0.01647949,\n",
              "       -0.15039062, -0.13183594,  0.12597656, -0.17480469,  0.02209473,\n",
              "       -0.1015625 ,  0.00817871,  0.10791016, -0.24609375, -0.109375  ,\n",
              "       -0.09375   , -0.01623535, -0.20214844,  0.23144531, -0.05444336,\n",
              "       -0.05541992, -0.20898438,  0.26757812,  0.27929688,  0.17089844,\n",
              "       -0.17578125, -0.02770996, -0.20410156,  0.02392578,  0.03125   ,\n",
              "       -0.25390625, -0.125     , -0.05493164, -0.17382812,  0.28515625,\n",
              "       -0.23242188,  0.0234375 , -0.20117188, -0.13476562,  0.26367188,\n",
              "        0.00769043,  0.20507812, -0.01708984, -0.12988281,  0.04711914,\n",
              "        0.22070312,  0.02099609, -0.29101562, -0.02893066,  0.17285156,\n",
              "        0.04272461, -0.19824219, -0.04003906, -0.16992188,  0.10058594,\n",
              "       -0.09326172,  0.15820312, -0.16503906, -0.06054688,  0.19433594,\n",
              "       -0.07080078, -0.06884766, -0.09619141, -0.07226562,  0.04882812,\n",
              "        0.07324219,  0.11035156,  0.04858398, -0.17675781, -0.33789062,\n",
              "        0.22558594,  0.16308594,  0.05102539, -0.08251953,  0.07958984,\n",
              "        0.08740234, -0.16894531, -0.02160645, -0.19238281,  0.03857422,\n",
              "       -0.05102539,  0.21972656,  0.08007812, -0.21191406, -0.07519531,\n",
              "       -0.15039062,  0.3046875 , -0.17089844,  0.12353516, -0.234375  ,\n",
              "       -0.10742188, -0.06787109,  0.01904297, -0.14160156, -0.22753906,\n",
              "       -0.16308594,  0.14453125, -0.15136719, -0.296875  ,  0.22363281,\n",
              "       -0.10205078, -0.0456543 , -0.21679688, -0.09033203,  0.09375   ,\n",
              "       -0.15332031, -0.01550293,  0.3046875 , -0.23730469,  0.08935547,\n",
              "        0.03710938,  0.02941895, -0.28515625,  0.15820312, -0.00306702,\n",
              "        0.06054688,  0.00497437, -0.15234375, -0.00836182,  0.02197266,\n",
              "       -0.12109375, -0.13867188, -0.2734375 , -0.06835938,  0.08251953,\n",
              "       -0.26367188, -0.16992188,  0.14746094,  0.08496094,  0.02075195,\n",
              "        0.13671875, -0.04931641, -0.0100708 , -0.00369263, -0.10839844,\n",
              "        0.14746094, -0.15527344,  0.16113281,  0.05615234, -0.05004883,\n",
              "       -0.1640625 , -0.26953125,  0.4140625 ,  0.06079102, -0.046875  ,\n",
              "       -0.02514648,  0.10595703,  0.1328125 , -0.16699219, -0.04907227,\n",
              "        0.04663086,  0.05151367, -0.07958984, -0.16503906, -0.29882812,\n",
              "        0.06054688, -0.15332031, -0.00598145,  0.06640625, -0.04516602,\n",
              "        0.24316406, -0.07080078, -0.36914062, -0.23144531, -0.11914062,\n",
              "       -0.08300781,  0.14746094, -0.05761719,  0.23535156, -0.12304688,\n",
              "        0.14648438,  0.13671875,  0.15429688,  0.02111816, -0.09570312,\n",
              "        0.05859375,  0.03979492, -0.08105469,  0.0559082 , -0.16601562,\n",
              "        0.27148438, -0.20117188, -0.00915527,  0.07324219,  0.10449219,\n",
              "        0.34570312, -0.26367188,  0.02099609, -0.40039062, -0.03417969,\n",
              "       -0.15917969, -0.08789062,  0.08203125,  0.23339844,  0.0213623 ,\n",
              "       -0.11328125,  0.05249023, -0.10449219, -0.02380371, -0.08349609,\n",
              "       -0.04003906,  0.01916504, -0.01226807, -0.18261719, -0.06787109,\n",
              "       -0.08496094, -0.03039551, -0.05395508,  0.04248047,  0.12792969,\n",
              "       -0.27539062,  0.28515625, -0.04736328,  0.06494141, -0.11230469,\n",
              "       -0.02575684, -0.04125977,  0.22851562, -0.14941406, -0.15039062],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look for closest words in meaning based on the closest vectors in the space."
      ],
      "metadata": {
        "id": "wsuKekCyFClT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAgKecjUmW_s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6aee9d1-0517-4d9d-f732-914d62c265f1"
      },
      "source": [
        "# get most similar words\n",
        "model.most_similar('yellow')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('red', 0.751919150352478),\n",
              " ('bright_yellow', 0.6869138479232788),\n",
              " ('orange', 0.6421886682510376),\n",
              " ('blue', 0.6376121640205383),\n",
              " ('purple', 0.6272757053375244),\n",
              " ('yellows', 0.612633228302002),\n",
              " ('pink', 0.6098285913467407),\n",
              " ('bright_orange', 0.5974606871604919),\n",
              " ('Warplanes_streaked_overhead', 0.583052396774292),\n",
              " ('participant_LOGIN', 0.5816755294799805)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can look for some analogies between words"
      ],
      "metadata": {
        "id": "5yV6I_EjFc3y"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN2VuE5UmPUm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6c51ae-c9a3-4ddd-a3ce-482a0f9b926d"
      },
      "source": [
        "# queen = (king - man) + woman\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7118193507194519)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhmQmasBmi2x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "525452fe-a51f-4674-c77e-bbe7947e4b26"
      },
      "source": [
        "# (france - paris) + spain = ?\n",
        "result = model.most_similar(positive=[\"paris\",\"spain\"], negative=[\"france\"], topn=1)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('madrid', 0.5295541882514954)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can use the model to find the word that doesn't match a list of words"
      ],
      "metadata": {
        "id": "l5lVpMykF5Hi"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w91o81Slm3aY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "69b25960-10c3-4f4b-d2ba-ccff13d76399"
      },
      "source": [
        "model.doesnt_match([\"red\", \"blue\", \"car\", \"orange\"])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'car'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR-cJcT-J9Xq"
      },
      "source": [
        "## Stanfordâs GloVe Embedding\n",
        "\n",
        "Like Word2Vec, the GloVe researchers also provide pre-trained word vectors. Let's download the smallest GloVe pre-trained model from the GloVe website. It's a 822 Megabyte zip file with 4 different models (50, 100, 200 and 300-dimensional vectors) trained on Wikipedia data with 6 billion tokens and a 400,000 word vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9WwmofxIIQJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f92791-597b-4bd8-cd3f-70f375eb303e"
      },
      "source": [
        "# download\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "\n",
        "# unzip downloaded word embeddings\n",
        "!unzip glove.6B.zip\n",
        "\n",
        "# list files in current directoty\n",
        "!ls -lah\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 21:25:15--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-02-18 21:25:15--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-02-18 21:25:15--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: âglove.6B.zipâ\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  3.55MB/s    in 2m 41s  \n",
            "\n",
            "2024-02-18 21:27:56 (5.11 MB/s) - âglove.6B.zipâ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "total 2.9G\n",
            "drwxr-xr-x 1 root root 4.0K Feb 18 21:28 .\n",
            "drwxr-xr-x 1 root root 4.0K Feb 18 21:08 ..\n",
            "drwxr-xr-x 4 root root 4.0K Feb 14 14:27 .config\n",
            "-rw-rw-r-- 1 root root 332M Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-rw-r-- 1 root root 662M Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root 990M Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root 164M Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip\n",
            "-rw-r--r-- 1 root root  17K Feb 18 21:09 model.bin\n",
            "drwxr-xr-x 1 root root 4.0K Feb 14 14:28 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Glove files are simple text files in the form of a dictionary. Words are key and dense vectors are values of key.\n",
        "\n",
        "So first we convert the GloVe file containing the word embeddings to the word2vec format for convenience of use. We can do it using the gensim library, a function called glove2word2vec."
      ],
      "metadata": {
        "id": "vhO2h6WnjZNV"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsXwAaiwI_1P"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Path to the GloVe file\n",
        "glove_input_file = 'glove.6B.100d.txt'\n",
        "# Specify the output format for the word2vec\n",
        "word2vec_output_file = 'glove.6B.100d.txt.word2vec'\n",
        "\n",
        "# Load the GloVe model as Word2Vec format\n",
        "# Note: Since the GloVe file is not in binary and does not have a header, set binary=False and no_header=True\n",
        "model = KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)\n",
        "\n",
        "# If you want to save this model in Word2Vec format for later use, you can do so:\n",
        "model.save_word2vec_format(word2vec_output_file, binary=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here **d** stands for dimension, 100d means, in this file each word has an equivalent vector of size 100.\n",
        "\n",
        "Now we can load the Glove embeddings in word2vec format and then analyze some analogies."
      ],
      "metadata": {
        "id": "tsSuDIBKjQEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the converted model\n",
        "\n",
        "filename = 'glove.6B.100d.txt.word2vec'\n",
        "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
      ],
      "metadata": {
        "id": "V20si4CBksYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MrEe17hdJEqB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e486b53-1299-46b2-f766-3de23a34b837"
      },
      "source": [
        "# calculate: (king - man) + woman = ?\n",
        "result = model.most_similar(positive=['woman', 'king'], negative=['man'], topn=1)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('queen', 0.7698540687561035)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the vectors associated with the words king and woman while subtracting man is equal to the vector associated with queen. In others words, subtracting the concept of man to the concept of King we get a representation of the \"royalty\". Then, if we sum to the woman word this concept we obtain the word \"queen\"."
      ],
      "metadata": {
        "id": "PQXUlOWQk-IN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Case Study: Text Classification with Word2Vec**"
      ],
      "metadata": {
        "id": "eT0B9uRg8jQ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we would like to use the word2vec model to extract features and at the top, we'll fit a binary classifier to distinguish positive reviews from negative ones. In other words, the output of the word2vec, which are the encoded vectors, represent the input to the classifier."
      ],
      "metadata": {
        "id": "ja64yujqkAbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading"
      ],
      "metadata": {
        "id": "nFHIcrbXtHtb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "We will use [the IMDB movie review dataset](http://ai.stanford.edu/~amaas/data/sentiment/), which consists of 50,000 movies review (50% are positive, 50% are negative)."
      ],
      "metadata": {
        "id": "qe8N_SOxtSDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download IMDB dataset\n",
        "!wget \"https://raw.githubusercontent.com/javaidnabi31/Word-Embeddding-Sentiment-Classification/master/movie_data.csv\" -O \"movie_data.csv\"\n",
        "\n",
        "# list files in current directory\n",
        "!ls -lah"
      ],
      "metadata": {
        "id": "3B-5AKC529VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "996320f0-5339-4010-a6d7-463c8e96c23e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-18 21:41:43--  https://raw.githubusercontent.com/javaidnabi31/Word-Embeddding-Sentiment-Classification/master/movie_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 65862309 (63M) [text/plain]\n",
            "Saving to: âmovie_data.csvâ\n",
            "\n",
            "movie_data.csv      100%[===================>]  62.81M   138MB/s    in 0.5s    \n",
            "\n",
            "2024-02-18 21:41:45 (138 MB/s) - âmovie_data.csvâ saved [65862309/65862309]\n",
            "\n",
            "total 3.3G\n",
            "drwxr-xr-x 1 root root 4.0K Feb 18 21:41 .\n",
            "drwxr-xr-x 1 root root 4.0K Feb 18 21:08 ..\n",
            "drwxr-xr-x 4 root root 4.0K Feb 14 14:27 .config\n",
            "-rw-rw-r-- 1 root root 332M Aug  4  2014 glove.6B.100d.txt\n",
            "-rw-r--r-- 1 root root 332M Feb 18 21:40 glove.6B.100d.txt.word2vec\n",
            "-rw-rw-r-- 1 root root 662M Aug  4  2014 glove.6B.200d.txt\n",
            "-rw-rw-r-- 1 root root 990M Aug 27  2014 glove.6B.300d.txt\n",
            "-rw-rw-r-- 1 root root 164M Aug  4  2014 glove.6B.50d.txt\n",
            "-rw-r--r-- 1 root root 823M Oct 25  2015 glove.6B.zip\n",
            "-rw-r--r-- 1 root root  17K Feb 18 21:09 model.bin\n",
            "-rw-r--r-- 1 root root  63M Feb 18 21:41 movie_data.csv\n",
            "drwxr-xr-x 1 root root 4.0K Feb 14 14:28 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# path to IMDB dataseet\n",
        "datapath = \"movie_data.csv\"\n",
        "\n",
        "# read file (dataset) into our program using pandas\n",
        "data = pd.read_csv(datapath)\n",
        "\n",
        "# display first 5 rows\n",
        "data.head()"
      ],
      "metadata": {
        "id": "GbrECsHB2_4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b8b44a4d-8442-4a11-e235-0d9c3b4ed61a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  I went and saw this movie last night after bei...          1\n",
              "1  Actor turned director Bill Paxton follows up h...          1\n",
              "2  As a recreational golfer with some knowledge o...          1\n",
              "3  I saw this film in a sneak preview, and it is ...          1\n",
              "4  Bill Paxton has taken the true story of the 19...          1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27f8bd87-1ed0-4661-ba54-5637e5ae8a3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27f8bd87-1ed0-4661-ba54-5637e5ae8a3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27f8bd87-1ed0-4661-ba54-5637e5ae8a3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27f8bd87-1ed0-4661-ba54-5637e5ae8a3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5f0317c9-e6b1-47d0-9306-1fb6d09fbd0e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5f0317c9-e6b1-47d0-9306-1fb6d09fbd0e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5f0317c9-e6b1-47d0-9306-1fb6d09fbd0e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Due to reading bad reviews and being told by friends that they couldn't believe how bad it was, I didn't go and see this film at the cinema. After watching it on DVD, I have to say I regret that now. I'm not saying it is brilliant, but I would venture to say that it is a good movie. I enjoyed it.<br /><br />People have skulls thicker than Ned's helmet if they go to see a movie like this and expect it to be a documentary. If you read up the actual history behind most movies based on historical figures, there is usually a huge difference between the fact and the fictional portrayal. I don't think Ganghis Kahn has ever once been portrayed even remotely close to historical fact. What kind of man Ned Kelly actually was is a matter of debate, and quite passionate it seems. In spite of the efforts of governments and some historians, Ned Kelly has become a legend. Legends are stories, and stories say as much about those who tell and listen to them as they do about the actual figure himself. Ned Kelly has become such a popular identity because he does represent that aspect of Australian culture that doesn't trust or accept authority. A society in which there is no dissent or challenge to authority is crazier and more dangerous than any bushranger.<br /><br />So not expecting this to be an accurate recreation of the historical Kelly gang, I actually found it a surprisingly unencumbered and refreshing movie. It was sentimental and romantic, but thankfully not anywhere as cheesy as it could have been; for my fellow Australians, watch 'The Lighthorseman' and you will see what I mean (it is a pity the way that story was treated so poorly). Perhaps the love affair business could have been forsaken for a bit more detail in other areas, such as the shooting of the troopers. Ironically, I actually enjoyed the movie because of that, because it would be those details that most of the focus on Ned's story would dwell. And they are the details of the story that are best discovered by reading the different viewpoints given by the various historians.<br /><br />This movie was always going to have a hard time, having make a compromise of appealing to a global movie market (to pay the pills) and the legend as it means to Australians; perhaps a little of Ned's spirit is in this movie, because I think it rebelled against people's expectations, and unfortunately missed both targets. Fortunately it made for an enjoyable quirk of a film. For me it was an unexpected kind of movie about Ned, and that is why I liked it. Orlando Bloom's performance did a lot for the movie too - he really added something. I think he would have enjoyed being the monster instead of the pretty elf, for a change.<br /><br />When you consider some other movies that are far worse than this one, your opinion of this movie should be reconsidered. Send me this on DVD for christmas rather than Croc Dundee or The Man From Snowy River anytime.\",\n          \"The funniest scene of this movie is probably when our saviours get their medals and plaques and whatnot. So the basic idea is, the police outnumbers these gangsters by like a million to one, but they're powerless because the villains' guns are just a bit bigger. I guess police ammo just kinda bounces of. They decided to shoot this movie in documentary style with fake interviews and all and seriously, what is wrong with these guys? They're talking like they were armed with rolled-up newspapers. Okay I admit, it's probably still dangerous to be in the line of the fire, even when the situation is so much to your advantage, but don't go nuts. And why the hell did it take 44 minutes to solve everything anyway? I'd say that's a very long time when you have them surrounded and you're allowed to shoot. They're like ten ft. away, they hit absolutely nothing. Then they go and buy bigger guns themselves to increase their heroism. And then yeah, there you have it, one of the cops actually hits someone. Bullet was probably diverted by a lamp post or something. I had a good laugh I guess.\",\n          \"Do not bother to waste your money on this movie. Do not even go into your car and think that you might see this movie if any others do not appeal to you. If you must see a movie this weekend, go see Batman again.<br /><br />The script was horrible. Perfectly written from the random horror movie format. Given: a place in confined spaces, a madman with various weapons, a curious man who manages to uncover all of the clues that honest police officers cannot put together, and an innocent and overly curious, yet beautiful and strong woman with whom many in the audience would love to be able to call their girlfriend. Mix together, add much poorly executed gore, and what the hell, let's put some freaks in there for a little \\\"spin\\\" to the plot.<br /><br />The acting was horrible, and the characters unbelievable - Borat was more believable than this.<br /><br />***Spoiler***and can someone please tell me how a butcher's vest can make a bullet ricochet from the person after being shot without even making the person who was shot flinch??? I'm in the army. We need that kind of stuff for ourselves.<br /><br />1 out of 10, and I would place it in the decimals of that rounded up to give it the lowest possible score I can.\"\n        ],\n        \"num_unique_values\": 49582,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "la5pMNObraCK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b494b9e-67af-4ca3-bff1-1fdbfaec3eee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Cleaning\n",
        "\n",
        "Text processing includes converting the text to lower case, removing non alphabetic characters, tokenization, stemming and/or lemmatization."
      ],
      "metadata": {
        "id": "79xlk1P9tXsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Text Cleaning\n",
        "import re\n",
        "import nltk\n",
        "#nltk.download('punkt')\n",
        "#nltk.download('stopwords')\n",
        "\n",
        "nltk.download('all')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "english_stopwords = stopwords.words('english')\n",
        "\n",
        "\n",
        "# define cleaning function\n",
        "def clean_text(text):\n",
        "  # convert to lower case\n",
        "  text = text.lower()\n",
        "\n",
        "  # remove non alphabetic characters ^\n",
        "  text = re.sub(r'[^a-z]', ' ', text)\n",
        "\n",
        "  # split into words\n",
        "  tokens = word_tokenize(text)\n",
        "\n",
        "  # Create WordNetLemmatizer object\n",
        "\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  # lemmatize and remove stopwords in one step\n",
        "  lemmatized = [lemmatizer.lemmatize(word, pos='v') for word in tokens if word not in english_stopwords]\n",
        "\n",
        "  # reconstruct the text from lemmatized tokens\n",
        "  text = ' '.join(lemmatized)\n",
        "\n",
        "\n",
        "\n",
        "  return text"
      ],
      "metadata": {
        "id": "qDagV7A7l3xe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82e63790-2265-4bdc-bad4-905fedeaacbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/alpino.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping\n",
            "[nltk_data]    |       taggers/averaged_perceptron_tagger_ru.zip.\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/basque_grammars.zip.\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/biocreative_ppi.zip.\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/bllip_wsj_no_aux.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown_tei.zip.\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_cat.zip.\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cess_esp.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/comparative_sentences.zip.\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/crubadan.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dolch.zip.\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/europarl_raw.zip.\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/floresta.zip.\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v15.zip.\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/framenet_v17.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply to all dataset\n",
        "\n",
        "data['clean_review'] = data['review'].apply(clean_text)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "losAnvaHmPBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "79913656-3dea-4473-9a50-9e596486afbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment  \\\n",
              "0  I went and saw this movie last night after bei...          1   \n",
              "1  Actor turned director Bill Paxton follows up h...          1   \n",
              "2  As a recreational golfer with some knowledge o...          1   \n",
              "3  I saw this film in a sneak preview, and it is ...          1   \n",
              "4  Bill Paxton has taken the true story of the 19...          1   \n",
              "\n",
              "                                        clean_review  \n",
              "0  go saw movie last night coax friends mine admi...  \n",
              "1  actor turn director bill paxton follow promise...  \n",
              "2  recreational golfer knowledge sport history pl...  \n",
              "3  saw film sneak preview delightful cinematograp...  \n",
              "4  bill paxton take true story us golf open make ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-04e699b8-df0d-4bd8-ad77-17ccbe6d57b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>clean_review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "      <td>go saw movie last night coax friends mine admi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "      <td>actor turn director bill paxton follow promise...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "      <td>recreational golfer knowledge sport history pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "      <td>saw film sneak preview delightful cinematograp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "      <td>bill paxton take true story us golf open make ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04e699b8-df0d-4bd8-ad77-17ccbe6d57b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-04e699b8-df0d-4bd8-ad77-17ccbe6d57b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-04e699b8-df0d-4bd8-ad77-17ccbe6d57b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c2fdec49-33cf-40e4-9c3f-db257ae27d9f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c2fdec49-33cf-40e4-9c3f-db257ae27d9f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c2fdec49-33cf-40e4-9c3f-db257ae27d9f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 50000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Due to reading bad reviews and being told by friends that they couldn't believe how bad it was, I didn't go and see this film at the cinema. After watching it on DVD, I have to say I regret that now. I'm not saying it is brilliant, but I would venture to say that it is a good movie. I enjoyed it.<br /><br />People have skulls thicker than Ned's helmet if they go to see a movie like this and expect it to be a documentary. If you read up the actual history behind most movies based on historical figures, there is usually a huge difference between the fact and the fictional portrayal. I don't think Ganghis Kahn has ever once been portrayed even remotely close to historical fact. What kind of man Ned Kelly actually was is a matter of debate, and quite passionate it seems. In spite of the efforts of governments and some historians, Ned Kelly has become a legend. Legends are stories, and stories say as much about those who tell and listen to them as they do about the actual figure himself. Ned Kelly has become such a popular identity because he does represent that aspect of Australian culture that doesn't trust or accept authority. A society in which there is no dissent or challenge to authority is crazier and more dangerous than any bushranger.<br /><br />So not expecting this to be an accurate recreation of the historical Kelly gang, I actually found it a surprisingly unencumbered and refreshing movie. It was sentimental and romantic, but thankfully not anywhere as cheesy as it could have been; for my fellow Australians, watch 'The Lighthorseman' and you will see what I mean (it is a pity the way that story was treated so poorly). Perhaps the love affair business could have been forsaken for a bit more detail in other areas, such as the shooting of the troopers. Ironically, I actually enjoyed the movie because of that, because it would be those details that most of the focus on Ned's story would dwell. And they are the details of the story that are best discovered by reading the different viewpoints given by the various historians.<br /><br />This movie was always going to have a hard time, having make a compromise of appealing to a global movie market (to pay the pills) and the legend as it means to Australians; perhaps a little of Ned's spirit is in this movie, because I think it rebelled against people's expectations, and unfortunately missed both targets. Fortunately it made for an enjoyable quirk of a film. For me it was an unexpected kind of movie about Ned, and that is why I liked it. Orlando Bloom's performance did a lot for the movie too - he really added something. I think he would have enjoyed being the monster instead of the pretty elf, for a change.<br /><br />When you consider some other movies that are far worse than this one, your opinion of this movie should be reconsidered. Send me this on DVD for christmas rather than Croc Dundee or The Man From Snowy River anytime.\",\n          \"The funniest scene of this movie is probably when our saviours get their medals and plaques and whatnot. So the basic idea is, the police outnumbers these gangsters by like a million to one, but they're powerless because the villains' guns are just a bit bigger. I guess police ammo just kinda bounces of. They decided to shoot this movie in documentary style with fake interviews and all and seriously, what is wrong with these guys? They're talking like they were armed with rolled-up newspapers. Okay I admit, it's probably still dangerous to be in the line of the fire, even when the situation is so much to your advantage, but don't go nuts. And why the hell did it take 44 minutes to solve everything anyway? I'd say that's a very long time when you have them surrounded and you're allowed to shoot. They're like ten ft. away, they hit absolutely nothing. Then they go and buy bigger guns themselves to increase their heroism. And then yeah, there you have it, one of the cops actually hits someone. Bullet was probably diverted by a lamp post or something. I had a good laugh I guess.\",\n          \"Do not bother to waste your money on this movie. Do not even go into your car and think that you might see this movie if any others do not appeal to you. If you must see a movie this weekend, go see Batman again.<br /><br />The script was horrible. Perfectly written from the random horror movie format. Given: a place in confined spaces, a madman with various weapons, a curious man who manages to uncover all of the clues that honest police officers cannot put together, and an innocent and overly curious, yet beautiful and strong woman with whom many in the audience would love to be able to call their girlfriend. Mix together, add much poorly executed gore, and what the hell, let's put some freaks in there for a little \\\"spin\\\" to the plot.<br /><br />The acting was horrible, and the characters unbelievable - Borat was more believable than this.<br /><br />***Spoiler***and can someone please tell me how a butcher's vest can make a bullet ricochet from the person after being shot without even making the person who was shot flinch??? I'm in the army. We need that kind of stuff for ourselves.<br /><br />1 out of 10, and I would place it in the decimals of that rounded up to give it the lowest possible score I can.\"\n        ],\n        \"num_unique_values\": 49582,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"clean_review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"perfect space fantasy film group kid go accidentally space get back sure would family film die sad want kate capsaw lead lady give golden globe performance sadly lea thompson win one suck bad say enough film great lea thompson lord perfect girl film film best sure br br sorry better star war star war rat space camp rat way around br br excellent r maybe iam good math\",\n          \"show last ten years deserve rare gem allow us escape back time things simpler fun fill heart laugh show keep laugh three decades difference furniture ugly clothe colorful even drug tolerable hair feather music accompany roller skate word merle haggard joint bad place take trip back greatest time american history fall love character feel good essence small town people nicer classic television much full house miss always remember shake groove thing\"\n        ],\n        \"num_unique_values\": 49576,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll take 10 000 entries of this dataset starting at index 20000 since the vectors computation takes a lot of time."
      ],
      "metadata": {
        "id": "AO_REM4Ptusb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Dataframe= data.iloc[20000:30000]\n"
      ],
      "metadata": {
        "id": "vQuvwLNN2MJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if dataset is balanced (number of positive sentiment = number of negative sentiment)\n",
        "# by plotting the different classes\n",
        "Dataframe.sentiment.value_counts().plot(kind = 'bar')\n",
        "\n",
        "# print the values count\n",
        "print(Dataframe.sentiment.value_counts())"
      ],
      "metadata": {
        "id": "3Wpf5SHcEgRy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "7a2cb96f-ee07-4ebd-cf9f-2d7d5b61034e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    5000\n",
            "1    5000\n",
            "Name: sentiment, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X=Dataframe['clean_review']\n",
        "Y=Dataframe['sentiment']"
      ],
      "metadata": {
        "id": "ClJIM5uAJQUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vec\n",
        "We'll use the Wor2Vec model trained on a part of the Google News dataset. The model contains 300-dimensional vectors for 3 million words and phrases."
      ],
      "metadata": {
        "id": "AUJe8UydvJn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "model = api.load(\"word2vec-google-news-300\")"
      ],
      "metadata": {
        "id": "lJ3AzmaC3flT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the encoded vector for our text data.\n",
        "\n",
        "***Instead of having a vector for each word, we'll average the value for each instance.***"
      ],
      "metadata": {
        "id": "TUw5i4vAko_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "# let's try it on one review\n",
        "\n",
        "for word in X[20002].split(' '):\n",
        "  word_vec=model[word]\n"
      ],
      "metadata": {
        "id": "UW5lQD3Uuq2J",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "outputId": "534564fb-0a1c-4d11-f4d1-d9e34998cbe3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"Key 'stylise' not present\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-97b77aea3836>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m20002\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mword_vec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \"\"\"\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey_or_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkey_or_keys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \"\"\"\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'stylise' not present\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, the model encounters words that are not part of the vocab on which the model was trained on; in this case we should decide what we want the model to do. In our case, words that are not part of the vocab will simply be ignored."
      ],
      "metadata": {
        "id": "RHr2q-xluFLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "#Start with an empty dataframe\n",
        "docs_vectors=pd.DataFrame()\n",
        "#create another empty dataframe to store each resulting output of the model\n",
        "temp=pd.DataFrame()\n",
        "for word in X[20000].split(' '):\n",
        "  try:\n",
        "    word_vec=model[word]\n",
        "    temp = pd.concat([temp, pd.DataFrame(word_vec).T], ignore_index=True)\n",
        "  except:\n",
        "    print(str(word), 'not in vocab, it will be ignored')\n",
        "doc_vector = temp.mean()\n",
        "docs_vectors = pd.concat([docs_vectors, pd.DataFrame(doc_vector).T], ignore_index=True)\n",
        "docs_vectors.shape"
      ],
      "metadata": {
        "id": "wJuHGsa2y1oP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41559a4f-075c-4563-9c6c-972bca8347c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ricci not in vocab, it will be ignored\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's loop over all the reviews and average their values."
      ],
      "metadata": {
        "id": "BKKMNaX9z3kd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute sentence vectors by averaging the word vectors for the words contained in the sentence\n",
        "docs_vectors=pd.DataFrame()\n",
        "\n",
        "for doc in X:\n",
        "  temp=pd.DataFrame()\n",
        "  for word in doc.split(' '):\n",
        "    try:\n",
        "      word_vec=model[word]\n",
        "      temp = pd.concat([temp, pd.DataFrame(word_vec).T], ignore_index=True)\n",
        "    except:\n",
        "      pass\n",
        "  doc_vector = temp.mean()\n",
        "  docs_vectors = pd.concat([docs_vectors, pd.DataFrame(doc_vector).T], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "517W1_eQ1lKP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_vectors.shape"
      ],
      "metadata": {
        "id": "QeusqAKqdDbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1779341-2ca9-4bba-a10a-42c62c0e2473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We end up with 10 000 vectors representing the 10 000 reviews, each one of size 300."
      ],
      "metadata": {
        "id": "JZ2_Ns-Mvoa1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Classification"
      ],
      "metadata": {
        "id": "xtghsP5jvwjj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output vectors of the Wor2Vec model, which represent the features extracted from the reviews, are the input to the classifier, Logistic Regression."
      ],
      "metadata": {
        "id": "PSlbxgL4v1g7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split (docs_vectors, Y , test_size=0.2)"
      ],
      "metadata": {
        "id": "5xxesGSslZeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# define the LogisticRegression classifier\n",
        "model = LogisticRegression()\n",
        "\n",
        "# train the classifier on the training data\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# get the mean accuracy on the training data\n",
        "acc_train = model.score(X_train,y_train)\n",
        "print('Training Accuracy:', acc_train)\n",
        "\n",
        "# get the mean accuracy on the training data\n",
        "acc_test = model.score(X_test,y_test)\n",
        "\n",
        "print('Testing Accuracy:', acc_test)"
      ],
      "metadata": {
        "id": "WA69R0dZdOYY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca31929-3c33-4cbe-8341-df1229ec22c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy: 0.8465\n",
            "Testing Accuracy: 0.849\n"
          ]
        }
      ]
    }
  ]
}